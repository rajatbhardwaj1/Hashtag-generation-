{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('song', 0.8404531478881836),\n",
       " ('music', 0.7873961329460144),\n",
       " ('singing', 0.7774211764335632),\n",
       " ('kelly', 0.7702898979187012),\n",
       " ('lyrics', 0.7667415142059326),\n",
       " ('beyonce', 0.7661986351013184),\n",
       " ('sound', 0.7640264630317688),\n",
       " ('makes', 0.762234091758728),\n",
       " ('chris', 0.7618743777275085),\n",
       " ('bad', 0.7614580988883972)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('voice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'what', 'just', 'please', 'hasnt', 'beside', 'across', 'various', 'next', 'except', 'de', 'two', 'again', 'could', 'seemed', 'make', 'made', 'well', 'was', 'whenever', 'anywhere', 'herself', 'something', 'anything', 'say', 'but', 'became', 'whatever', 'yet', 'fire', 'your', 'on', 'nowhere', 'us', 'here', 'ourselves', 'more', 'hereafter', 'therein', 'they', 'how', 'does', 'do', 'call', 'if', 'have', 'must', 'by', 'his', 'at', 'however', 'had', 'twelve', 'itself', 'used', 'their', 'computer', 'is', 'ie', 'might', 'part', 'whence', 'amongst', 'take', 'anyone', 'whom', 'become', 'less', 'not', 'when', 'eleven', 'see', 'such', 'beyond', 'of', 'the', 'ten', 'thru', 'can', 'yourselves', 'seem', 'almost', 'herein', 'cant', 'along', 'through', 'myself', 'kg', 'whither', 'although', 'cannot', 'without', 'elsewhere', 'around', 'she', 'cry', 'much', 'until', 'eight', 'neither', 'sometime', 'some', 'bill', 'down', 'whose', 'everywhere', 'go', 'three', 'where', 'themselves', 'enough', 'found', 'while', 'becoming', 'thin', 'which', 'front', 'same', 'sixty', 'ours', 'everything', 'hundred', 'really', 'that', 'rather', 'seeming', 'via', 'besides', 'so', 'noone', 'most', 'he', 'will', 'any', 'already', 'often', 'amoungst', 'detail', 'beforehand', 'thereby', 'top', 'once', 'may', 'alone', 'hers', 'meanwhile', 'hereupon', 'him', 'latter', 'move', 'five', 'within', 'own', 'perhaps', 'another', 'a', 'to', 'in', 'up', 'since', 'anyhow', 'first', 'moreover', 'ltd', 'you', 'under', 'our', 'them', 'otherwise', 'out', 'after', 'inc', 'below', 'couldnt', 'give', 'empty', 'among', 'others', 'find', 'into', 'being', 'none', 'whoever', 'one', 'anyway', 'those', 'amount', 'now', 'never', 'whole', 'last', 'between', 'etc', 'whereafter', 'fill', 'onto', 'yourself', 'over', 'wherein', 'than', 'for', 'also', 'did', 'whereby', 'further', 'therefore', 'even', 'name', 'someone', 're', 'con', 'as', 'has', 'namely', 'thereafter', 'who', 'serious', 'been', 'i', 'would', 'ever', 'yours', 'be', 'former', 'unless', 'nothing', 'always', 'using', 'indeed', 'somewhere', 'doesn', 'least', 'there', 'her', 'both', 'hence', 'every', 'regarding', 'thence', 'six', 'should', 'am', 'wherever', 'sometimes', 'each', 'co', 'upon', 'about', 'before', 'per', 'from', 'side', 'interest', 'four', 'everyone', 'un', 'throughout', 'because', 'km', 'toward', 'third', 'thus', 'either', 'forty', 'we', 'together', 'due', 'seems', 'get', 'bottom', 'doing', 'whereupon', 'thick', 'afterwards', 'thereupon', 'sincere', 'behind', 'other', 'these', 'towards', 'nobody', 'and', 'many', 'mine', 'himself', 'only', 'eg', 'several', 'hereby', 'are', 'why', 'nine', 'keep', 'system', 'all', 'show', 'mostly', 'still', 'didn', 'whether', 'against', 'too', 'describe', 'twenty', 'latterly', 'were', 'quite', 'very', 'done', 'whereas', 'though', 'don', 'few', 'then', 'put', 'somehow', 'fifty', 'its', 'off', 'no', 'mill', 'or', 'above', 'else', 'fifteen', 'back', 'an', 'during', 'me', 'formerly', 'full', 'nor', 'this', 'with', 'becomes', 'nevertheless', 'my', 'it'})\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "print(STOPWORDS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'4'})\n",
      "['1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "l = ['1' ,'2' , '3']\n",
    "m = ['2' , '4']\n",
    "p = frozenset(l)\n",
    "p1 = frozenset(m)\n",
    "print(p1.difference(p))\n",
    "ll = list(p)\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [07/Mar/2022 22:06:31] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Mar/2022 22:06:36] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Mar/2022 22:07:11] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Mar/2022 22:07:18] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def my_form():\n",
    "    return render_template('my-form.html')\n",
    "\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def my_form_post():\n",
    "    text = request.form['text']\n",
    "    number = request.form['number']\n",
    "\n",
    "    list_of_words = text.split()\n",
    "\n",
    "    hashtags_list = []\n",
    "    most_similar_vec = []\n",
    "\n",
    "    for word in list_of_words:\n",
    "        hashtags_list.append(word.lower())\n",
    "        if glove_vectors.__contains__(word):\n",
    "\n",
    "            most_similar_vec = glove_vectors.most_similar(word)\n",
    "            count = 0\n",
    "\n",
    "            for word_1, similarity in most_similar_vec:\n",
    "\n",
    "                hashtags_list.append(word_1)\n",
    "                count = count + 1\n",
    "\n",
    "    # finding the cosine similarity of the generated words with the entire entered text and sorting it in decending order w.r.t similarity\n",
    "\n",
    "    final_list = []\n",
    "    for hash_word in hashtags_list:\n",
    "        cosine_sim = 0\n",
    "        # not including words with length less or equal to 4\n",
    "        if len(hash_word) <= 3:\n",
    "            continue\n",
    "        for word in text:\n",
    "\n",
    "            # checking if the input word is in the vocabulary\n",
    "            if glove_vectors.__contains__(word) and glove_vectors.__contains__(hash_word):\n",
    "                # comparing each word of the generated word with the entire text\n",
    "                cosine_sim = cosine_sim + \\\n",
    "                    glove_vectors.similarity(word, hash_word)\n",
    "\n",
    "        final_list.append((hash_word, cosine_sim))\n",
    "\n",
    "    # sorting with respect to total cosine similarity in increasing order\n",
    "    # words having high total cosine similarity are not good hashtags\n",
    "\n",
    "    final_list.sort(key=lambda x: x[1])\n",
    "\n",
    "    count = 0\n",
    "    # removing duplicates\n",
    "    newlist = sorted(set(final_list), key=lambda x: final_list.index(x))\n",
    "\n",
    "    #extracting the words from pair of word , similarity in newlist (making list of string from list of pair of string , float)\n",
    "\n",
    "    newlist1 = [] \n",
    "\n",
    "    for word , similarity in newlist:\n",
    "        newlist1.append(word) \n",
    "    \n",
    "    #removing the stop words from the newlist \n",
    "\n",
    "    #converting the newlist to frozenset \n",
    "\n",
    "    newlist1_frozen = frozenset(newlist1)\n",
    "\n",
    "    #taking the difference from the stopwords\n",
    "\n",
    "    newlist1_frozen = newlist1_frozen.difference(STOPWORDS)\n",
    "\n",
    "    # coverting the set back to the list \n",
    "\n",
    "    newlist1 = list(newlist1_frozen)\n",
    "    processed_text = \"\"\n",
    "\n",
    "    ct = 0\n",
    "\n",
    "    for word in newlist1:\n",
    "\n",
    "        processed_text = processed_text+'#'+word + ' '\n",
    "\n",
    "        ct = ct + 1\n",
    "\n",
    "        if str(ct) == number:\n",
    "            break\n",
    "\n",
    "    return render_template('result.html', result=processed_text)\n",
    "\n",
    "\n",
    "app.run(host='localhost', port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a7853f465984184c2db926f12cf0514f49bd82ebd08c64e7d47bb74214f72b4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
